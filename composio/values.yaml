# Development values for Composio
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Namespace configuration
# If create is true, the chart will create namespaces needed by services
# If create is false, you need to create namespaces externally before deploying
namespace:
  create: false
  # Name of the namespace where Composio services will be deployed
  # If not specified, defaults to "composio"
  name: "composio"

global:
  environment: development
  domain: localhost
  registry: 
    name: "008971668139.dkr.ecr.us-east-1.amazonaws.com"
  imagePullSecrets:
    - name: ecr-secret
  # Add global security defaults for GKE Autopilot

# External secrets configuration
# Pass these during helm install using --set flags:
# --set externalSecrets.ecr.token="$(aws ecr get-login-password --region us-east-1)"
# --set externalSecrets.redis.url="redis://user:pass@host:port"
externalSecrets:
  # ECR authentication
  ecr:
    token: ""
    server: "008971668139.dkr.ecr.us-east-1.amazonaws.com"
    username: "AWS"

# Global secrets configuration for development
# All secrets will be auto-generated for security

externalPostgreSQL:
  enabled: true

# External Redis configuration
# To use external Redis:
# 1. Set externalRedis.enabled: true
# 2. Set redis.enabled: false
# 3. Provide Redis URL via: --set externalSecrets.redis.url="redis://user:pass@host:port/db"
externalRedis:
  enabled: true
    
redis:
  # Note: Set enabled to false when using external Redis (externalRedis.enabled: true)
  enabled: false
  auth:
    enabled: true
    password: "redis123"
  architecture: standalone
  master:
    persistence:
      enabled: true
      size: 8Gi
    resources:
      requests:
        memory: "4Gi"
        cpu: "2"
      limits:
        memory: "4Gi"
        cpu: "2"
    # Disable privileged sysctls for GKE Autopilot
    sysctlImage:
      enabled: false
    sysctl:
      enabled: false


# Apollo service configuration - Development
apollo:
  replicaCount: 2
  image:
    repository: composio-self-host/apollo
    tag: "495d325"
    pullPolicy: Always
  nodeSelector: {}
  tolerations: []
  affinity: {} 
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000

  containerSecurityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    capabilities:
      drop:
        - ALL
  # Apollo DB init container configuration
  dbInit:
    enabled: true
    image:
      repository: composio-self-host/apollo-db-init
      tag: "495d325"
      pullPolicy: Always
    podSecurityContext:
      runAsUser: 1000
      runAsGroup: 3000
      fsGroup: 2000

    containerSecurityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      readOnlyRootFilesystem: false
      capabilities:
        drop:
          - ALL

  
  service:
    type: NodePort
    port: 9900
    nodePort: 30900
  
  resources:
    requests:
      memory: "5Gi"
      cpu: "1"
    limits:
      memory: "6Gi"
      cpu: "1"
  
  database:
    urlSecret:
      name: "external-postgres-secret"
      key: "url"
  
  # Note: Secrets are now managed globally in the 'secrets' section
  
  # HPA (Horizontal Pod Autoscaler) configuration
  autoscaling:
    enabled: false
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
    # Scaling behavior configuration
    scaleDownStabilizationWindowSeconds: 300
    scaleDownPercent: 10
    scaleDownPeriodSeconds: 60
    scaleUpStabilizationWindowSeconds: 60
    scaleUpPercent: 100
    scaleUpPeriodSeconds: 15
    scaleUpPods: 4

# Thermos service configuration - Development
thermos:
  replicaCount: 2
  image:
    repository: composio-self-host/thermos
    tag: "495d325"
    pullPolicy: Always
  
  nodeSelector: {}
  tolerations: []
  affinity: {}
  
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
  
  containerSecurityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
  
  # Thermos DB init container configuration
  dbInit:
    enabled: true
    image:
      repository: composio-self-host/thermos-db-init
      tag: "495d325"
      pullPolicy: Always
    
    podSecurityContext:
      runAsUser: 1000
      runAsGroup: 3000
      fsGroup: 2000
  
    containerSecurityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      readOnlyRootFilesystem: true
      capabilities:
        drop:
          - ALL
  
  service:
    type: ClusterIP
    port: 8180
  
  resources:
    requests:
      memory: "4Gi"
      cpu: "2"
    limits:
      memory: "5Gi"
      cpu: "2"
  
  # Note: Secrets are now managed globally in the 'secrets' section
  
  # HPA (Horizontal Pod Autoscaler) configuration
  autoscaling:
    enabled: false
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
    # Scaling behavior configuration
    scaleDownStabilizationWindowSeconds: 300
    scaleDownPercent: 10
    scaleDownPeriodSeconds: 60
    scaleUpStabilizationWindowSeconds: 60
    scaleUpPercent: 100
    scaleUpPeriodSeconds: 15
    scaleUpPods: 4

# DB Init configuration for Jobs (runs once per deployment)
dbInit:
  adminEmail: "hello@composio.dev"
  # Job configuration
  job:
    backoffLimit: 3
    activeDeadlineSeconds: 1200
    restartPolicy: OnFailure

# Temporal configuration - Using official helm chart as dependency with external PostgreSQL
temporal:
  fullnameOverride: "temporal-stack"
  
  server:
    enabled: true
    livenessProbe:
      enabled: false
      # httpGet:
      #   path: /api/health
      #   port: 3000
      # initialDelaySeconds: 120
      # timeoutSeconds: 10

    readinessProbe:
      enabled: false
      # httpGet:
      #   path: /api/health
      #   port: 3000
      #   scheme: HTTP
      # failureThreshold: 3
      # initialDelaySeconds: 30
      # periodSeconds: 10
      # successThreshold: 1
      # timeoutSeconds: 1

    replicaCount: 2
    image:
      repository: temporalio/server
      tag: 1.28.0
      pullPolicy: IfNotPresent
    
    config:
      logLevel: "info"
      numHistoryShards: 512
      
      # Configure persistence to use PostgreSQL from external secret
      persistence:
        defaultStore: default
        
        # Main temporal database  
        default:
          driver: "sql"
          sql:
            driver: "postgres12"
            host: "override_some_ip_address_here"
            port: 5432
            database: "temporal"
            user: "postgres"
            existingSecret: "external-postgres-secret"
            maxConns: 20
            maxIdleConns: 20
            maxConnLifetime: "1h"
        
        # Visibility database (will be created by schema setup)
        visibility:
          driver: "sql" 
          sql:
            driver: "postgres12"
            host: "override_some_ip_address_here"
            port: 5432
            database: "temporal_visibility"
            user: "postgres"
            existingSecret: "external-postgres-secret"
            maxConns: 20
            maxIdleConns: 20
            maxConnLifetime: "1h"
      namespaces:
        # Enable this to create namespaces
        create: true
        namespace:
          - name: default
            retention: 7d

    # Frontend service configuration
    frontend:
      livenessProbe:
        enabled: false
        # httpGet:
        #   path: /api/health
        #   port: 3000
        # initialDelaySeconds: 120
        # timeoutSeconds: 10

      readinessProbe:
        enabled: false
        # httpGet:
        #   path: /api/health
        #   port: 3000
        #   scheme: HTTP
        # failureThreshold: 3
        # initialDelaySeconds: 30
        # periodSeconds: 10
        # successThreshold: 1
        # timeoutSeconds: 1
      service:
        type: ClusterIP
        port: 7233
        membershipPort: 6933
        httpPort: 7243

  # Enable schema setup to create temporal databases
  schema:
    createDatabase:
      enabled: true
    setup:
      enabled: true
      backoffLimit: 100
    update:
      enabled: true
      backoffLimit: 100

  # Enable web UI
  web:
    enabled: true
    replicaCount: 1
    image:
      repository: temporalio/ui
      tag: 2.38.3
      pullPolicy: IfNotPresent
    service:
      type: ClusterIP
      port: 8080
    livenessProbe:
      enabled: false
      # httpGet:
      #   path: /api/health
      #   port: 3000
      # initialDelaySeconds: 120
      # timeoutSeconds: 10

    readinessProbe:
      enabled: false
      # httpGet:
      #   path: /api/health
      #   port: 3000
      #   scheme: HTTP
      # failureThreshold: 3
      # initialDelaySeconds: 30
      # periodSeconds: 10
      # successThreshold: 1
      # timeoutSeconds: 1
    service:
      type: ClusterIP
      port: 7233
      membershipPort: 6933
      httpPort: 7243

  
  admintools:
    livenessProbe:
      enabled: false
      # httpGet:
      #   path: /api/health
      #   port: 3000
      # initialDelaySeconds: 120
      # timeoutSeconds: 10

    readinessProbe:
      enabled: false
      # httpGet:
      #   path: /api/health
      #   port: 3000
      #   scheme: HTTP
      # failureThreshold: 3
      # initialDelaySeconds: 30
      # periodSeconds: 10
      # successThreshold: 1
      # timeoutSeconds: 1
    enabled: true
    image:
      repository: temporalio/admin-tools
      tag: 1.28.0-tctl-1.18.2-cli-1.3.0
      pullPolicy: IfNotPresent

  cassandra:
    enabled: false
    image:
      repo: cassandra
      tag: 3.11.3
      pullPolicy: IfNotPresent
  mysql:
    enabled: false
  elasticsearch:
    enabled: false
    imageTag: 7.17.3
    
  prometheus:
    enabled: false
    nodeExporter:
      enabled: false
  grafana:
    enabled: false

prometheus:
  enabled: false
  nodeExporter:
    enabled: false
  imagePullSecrets: []

grafana:
  enabled: false
  replicas: 1

testFramework:
  enabled: false

rbac:
  create: false
  pspEnabled: false
  namespaced: true

elasticsearch:
  enabled: false

cassandra:
  enabled: false

ingress:
  enabled: false

serviceAccount:
  create: true
  annotations: {}
  name: ""

nodeSelector: {}

tolerations: []

affinity: {}

# OpenTelemetry configuration
otel:
  enabled: true
  
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000

  containerSecurityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
  exporter:
    otlp:
      endpoint: "composio-otel-collector:4317"  # gRPC endpoint without http://
      tracesEndpoint: "composio-otel-collector:4317"  # Traces endpoint
      metricsEndpoint: "composio-otel-collector:4317"  # Metrics endpoint
      insecure: true
      headers: ""  # Optional headers for authentication
  traces:
    enabled: true
    sampler: "always_on"  # Sampling strategy: always_on, always_off, traceidratio
    samplerArg: 1.0  # Sampling ratio (0.0 to 1.0)
  metrics:
    enabled: true
    exportInterval: 60000  # milliseconds
  logs:
    enabled: false  # Enable if you want to collect logs via OTEL
  environment: "development"
  # Service-specific configurations
  apollo:
    serviceName: "apollo"
    serviceVersion: "1.0.0"
    metricsEndpoint: "http://composio-otel-collector:4318/v1/metrics"  # HTTP endpoint for metrics
  thermos:
    serviceName: "thermos"
    serviceVersion: "1.0.0"
    metricsEndpoint: "http://composio-otel-collector:4318/v1/metrics"  # HTTP endpoint for metrics
  mercury:
    serviceName: "mercury-openapi"
    serviceVersion: "1.0.0"
    metricsEndpoint: "http://composio-otel-collector:4318/v1/metrics"  # HTTP endpoint for metrics
  
  # OpenTelemetry Collector configuration
  collector:
    enabled: true
    replicaCount: 1
    image:
      repository: otel/opentelemetry-collector-contrib
      tag: "0.91.0"
      pullPolicy: IfNotPresent
    
    service:
      type: ClusterIP
      ports:
        otlp:
          port: 4317
          targetPort: 4317
          protocol: TCP
        otlp-http:
          port: 4318
          targetPort: 4318
          protocol: TCP
        jaeger:
          port: 14250
          targetPort: 14250
          protocol: TCP
        prometheus:
          port: 8889
          targetPort: 8889
          protocol: TCP
    
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
    
    # Google Cloud configuration
    googleCloud:
      enabled: true
      projectId: "self-host-kubernetes"
      serviceAccount:
        create: true
        name: "otel-collector"
        annotations:
          iam.gke.io/gcp-service-account: "otel-collector@self-host-kubernetes.iam.gserviceaccount.com"
    
    # Collector configuration
    config:
      # Exporters configuration - send to Google Cloud
      exporters:
        # Console exporter for debugging
        debug:
          verbosity: basic
        # Prometheus exporter for metrics
        prometheus:
          endpoint: "0.0.0.0:8889"
        # Google Cloud exporter for metrics and traces
        googlecloud:
          project: "self-host-kubernetes"
          metric:
            prefix: "composio/"
          trace: {}
      
      # Processors for data transformation
      processors:
        batch:
          timeout: 1s
          send_batch_size: 1024
        memory_limiter:
          limit_mib: 512
          check_interval: 1s
      
      # Receivers to collect telemetry data
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: "0.0.0.0:4317"
            http:
              endpoint: "0.0.0.0:4318"
        jaeger:
          protocols:
            grpc:
              endpoint: "0.0.0.0:14250"
      
      # Extensions for additional functionality
      extensions:
        health_check:
          endpoint: "0.0.0.0:13133"
        pprof:
          endpoint: "0.0.0.0:1777"
        zpages:
          endpoint: "0.0.0.0:55679"
      
      # Service pipelines
      service:
        extensions: [health_check, pprof, zpages]
        pipelines:
          traces:
            receivers: [otlp, jaeger]
            processors: [memory_limiter, batch]
            exporters: [debug, googlecloud]  # Export to Google Cloud Trace
          metrics:
            receivers: [otlp]
            processors: [memory_limiter, batch]
            exporters: [debug, prometheus, googlecloud]  # Export to Google Cloud Monitoring

# AWS configuration - disabled for development
aws:
  region: us-east-1
  s3:
    lambdaBucketName: "tools"
  lambda:
    functionName: "mercury"
    
# Minio configuration - Development
minio:
  replicaCount: 1
  
  # Deployment strategy to prevent Multi-Attach volume errors
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000

  containerSecurityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    capabilities:
      drop:
        - ALL

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # Allow old pod to terminate first
      maxSurge: 0        # Don't create new pod until old one is gone
  
  image:
    repository: composio-self-host/minio
    tag: "495d325"
    pullPolicy: Always
  
  service:
    type: ClusterIP
  
  auth:
    rootUser: "minioadmin"
    rootPassword: "minioadmin123"
  
  persistence:
    enabled: true
    size: 8Gi
    accessMode: ReadWriteOnce
    storageClass: ""
  
  resources:
    requests:
      memory: "4Gi"
      cpu: "2"
    limits:
      memory: "4Gi"
      cpu: "2"
  
  livenessProbe:
    httpGet:
      path: /minio/health/live
      port: 9000
    initialDelaySeconds: 120
    periodSeconds: 30
  
  readinessProbe:
    httpGet:
      path: /minio/health/ready
      port: 9000
    initialDelaySeconds: 30
    periodSeconds: 10
  
  extraEnvVars: []

# Mercury service configuration - Development
mercury:
  enabled: true
  useKnative: true
  replicaCount: 1
  image:
    repository: composio-self-host/mercury
    tag: "495d325"
    pullPolicy: Always
  
  # Let the container use its default entrypoint
  # command: []
  # args: []
  
  nodeSelector: {}
  tolerations: []
  affinity: {} 

  livenessProbe:
    enabled: false
    # httpGet:
    #   path: /api/health
    #   port: 3000
    # initialDelaySeconds: 120
    # timeoutSeconds: 10

  readinessProbe:
    enabled: false
    # httpGet:
    #   path: /api/health
    #   port: 3000
    #   scheme: HTTP
    # failureThreshold: 3
    # initialDelaySeconds: 30
    # periodSeconds: 10
    # successThreshold: 1
    # timeoutSeconds: 1

  service:
    type: ClusterIP
    port: 8080
  
  autoscaling:
    minScale: 1
    maxScale: 10
    target: 80
  
  containerConcurrency: 0
  timeoutSeconds: 300
  
  resources:
    requests:
      memory: "2Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "2"
      
  knative:
    minReplicas: 1
    replicas: 2
    maxReplicas: 5

  securityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    runAsUser: 1000
    capabilities:
      drop:
      - ALL
    seccompProfile:
      type: RuntimeDefault
  
  ingress:
    enabled: false
    className: ""
    annotations: {}
    host: ""
    tls: []
  
  volumeMounts: []
  volumes: []
  

supportBundle:
  # Enable/disable support bundle functionality
  enabled: false
  
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000

  containerSecurityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL

  # Email address for support ticket submissions
  supportEmail: "support@composio.dev"
  
  # Troubleshoot.sh version to use
  troubleshootVersion: "v0.84.0"
  
  # Output path for support bundles (inside container)
  outputPath: "/tmp/support-bundle"
  
  # Run in non-interactive mode
  interactive: false
  
  # Enable automatic redaction of sensitive data
  redact: true
  
  # Resource limits for support bundle job
  resources:
    limits:
      memory: "512Mi"
      cpu: "500m"
    requests:
      memory: "256Mi"
      cpu: "100m"
  
  # Persistence for support bundle storage
  persistence:
    enabled: false
    size: "1Gi"
    storageClass: ""  # Uses default storage class if empty
    
  # Collector configuration
  collectors:
    # Enable metrics collection (requires Prometheus)
    metrics:
      enabled: false
      
    # Enable database connectivity checks
    database:
      enabled: false
  
  # Analyzer configuration  
  analyzers:
    # Minimum cluster requirements
    minNodes: 1
    minMemoryGB: 2
    minCPU: 1
    
    # Enable custom log analysis
    customChecks: true
    
  # Custom collectors (advanced users)
  customCollectors: []
    # Example:
    # - logs:
    #     selector:
    #       - app=my-custom-app
    #     namespace: custom-namespace
    #     limits:
    #       maxAge: 168h
    #       maxLines: 5000
  
  # Custom analyzers (advanced users) 
  customAnalyzers: []
    # Example:
    # - textAnalyze:
    #     checkName: "Custom Error Check"
    #     fileName: "*/logs/*/*.log"
    #     regex: "CUSTOM_ERROR"
    #     outcomes:
    #       - fail:
    #           when: "true"
    #           message: "Custom error detected"
    
  # Additional redactors
  customRedactors: []
    # Example:
    # - name: "Custom Redactor"
    #   file: "*/logs/*/*.log"
    #   regex:
    #     - 'custom_secret=([^&\s]+)'
    #   replacements:
    #     - 'custom_secret=***HIDDEN***'
